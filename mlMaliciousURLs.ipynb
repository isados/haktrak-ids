{
 "cells": [
  {
   "source": [
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d70b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from utils import get_configs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "configvars = get_configs()"
   ]
  },
  {
   "source": [
    "## Read datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443cdb7d",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 URL Label\n",
       "0  http://astore.amazon.co.uk/allezvinsfrenchr/de...  Spam\n",
       "1  http://archive.salisburyjournal.co.uk/2007/3/6...  Spam\n",
       "2     http://appbasic.jettons.co.uk/links/index.html  Spam\n",
       "3  http://archive.yorkpress.co.uk/2003/11/6/25684...  Spam\n",
       "4  http://acard4u.co.uk/product_reviews.php?cPath...  Spam"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URL</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://astore.amazon.co.uk/allezvinsfrenchr/de...</td>\n      <td>Spam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://archive.salisburyjournal.co.uk/2007/3/6...</td>\n      <td>Spam</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://appbasic.jettons.co.uk/links/index.html</td>\n      <td>Spam</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://archive.yorkpress.co.uk/2003/11/6/25684...</td>\n      <td>Spam</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://acard4u.co.uk/product_reviews.php?cPath...</td>\n      <td>Spam</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "\n",
    "base_df = pd.read_csv(configvars['BaseDataset']['malicious-urls']['og'])\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = base_df['URL'], base_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Defacement    0.583294\n",
       "Benign        0.213938\n",
       "Spam          0.072566\n",
       "Malware       0.069942\n",
       "Phishing      0.060260\n",
       "Name: Label, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['google', 'com']\n['https', 'google', 'so', 'not', 'fake', 'com', 'fake=False&seriously=True']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "def custom_tokenizer(string):\n",
    "    final = []\n",
    "    tokens = [a for a in list(urlparse(string)) if a]\n",
    "    for t in tokens:\n",
    "        final.extend(re.compile(\"[.-]\").split(t))\n",
    "    return final\n",
    "print (custom_tokenizer('google.com'))\n",
    "print(custom_tokenizer('https://google-so-not-fake.com?fake=False&seriously=True'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function custom_tokenizer at 0x7f8ff7d04b80>)),\n",
       "                ('model', RidgeClassifier())])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vect = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "rc = RidgeClassifier()\n",
    "rc_pipe = Pipeline([('vect', vect), ('model', rc)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "scores = cross_val_score(rc_pipe, X_train, y_train, cv=5)\n",
    "scores.mean() # not good enough!!\n",
    "\n",
    "rc_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = rc_pipe.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}